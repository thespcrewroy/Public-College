{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167077c7-9cf7-47e0-a1bc-94f618bc700c",
   "metadata": {},
   "source": [
    "### Building a sklearn Pipeline - Example ###\n",
    "\n",
    "This exercise is about building a pipeline for preprocessing, save the model and use saved model for prediction.\n",
    "\n",
    "I have created a synthetic dataset that includes scaling requirement, missing value imputation, and categorical to numeric conversion. \n",
    "\n",
    "Don't worry about accuracy as it is conjured up data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75262d63-5e80-49e1-8e32-850017549e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# New Imports\n",
    "from sklearn.compose import ColumnTransformer # used to apply different preprocessing to different columns\n",
    "from sklearn.pipeline import Pipeline # used to chain together different transformers\n",
    "from sklearn.impute import SimpleImputer # used to fill in missing values\n",
    "import joblib # used to save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24c45ce-8dfb-4729-9477-62187edb47c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:     age   income  gender  education  label\n",
      "0  37.0  45749.0  female        PhD      1\n",
      "1  69.0  73161.0    male        PhD      1\n",
      "2  23.0  47514.0    male  bachelors      1\n",
      "3  29.0  45953.0  female    masters      1\n",
      "4  54.0  89857.0    male        PhD      1\n",
      "5  69.0  39660.0     NaN    masters      0\n",
      "6  35.0  49887.0     NaN  bachelors      1\n",
      "7  61.0  80866.0     NaN        PhD      0\n",
      "8  22.0  30073.0     NaN    masters      0\n",
      "9  67.0  22538.0     NaN    masters      0\n",
      "Missing values in different features:\n",
      "age          10\n",
      "income       10\n",
      "gender       10\n",
      "education     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('data.csv') # read in the data\n",
    "\n",
    "print(f\"Data: {data.head(10)}\") # print the first 10 rows of the data\n",
    "\n",
    "X = data.drop('label',axis=1) # seperate the features from the labels\n",
    "y = data['label'] # set the labels\n",
    "print(f\"Missing values in different features:\\n{X.isna().sum()}\") # print the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65306849-ae9f-4cf2-afc8-7e7e7a28ab2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the type of features to make it easier to define which colums should be processed by the column transformer\n",
    "\n",
    "numerical_features = ['age', 'income'] # numerical features\n",
    "categorical_features = ['gender', 'education'] # categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d376e5-fcaa-42bd-a4d4-45b1e776ec16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # split the data into training and testing sets\n",
    "\n",
    "# Build the pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # fill in missing values with the mean of the column\n",
    "    ('scaler', StandardScaler()) # scale the data\n",
    "]) # Numeric transformer\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # fill in missing values with the mode of the column\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')) # encode the categorical data\n",
    "]) # Categorical transformer only works on categorical data\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features), # use the numeric_transformer on the numerical_features\n",
    "        ('cat', categorical_transformer, categorical_features) # use the categorical_transformer on the categorical_features\n",
    "    ]) # Combine the transformers into a single preprocessor\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), # Apply the preprocessor to the data\n",
    "    ('model', RandomForestClassifier()) # Use a random forest classifier\n",
    "]) # Combine the preprocessor and the model into a single pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9b5e84-a04c-45ad-8564-3d958aa6411b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and make predictions\n",
    "pipeline.fit(X_train, y_train) # Fit the pipeline on training data\n",
    "y_pred = pipeline.predict(X_test) # Make predictions on test data\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred) # Calculate the accuracy of the model\n",
    "print(f\"Accuracy: {accuracy:.2f}\") # Print the accuracy of the model (low accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3a9099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_pipeline.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'model_pipeline.pkl') # Save the entire pipeline (including preprocessing and model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce444289-a5fb-489d-95e8-7833222013e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Predictions:\n",
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = joblib.load('model_pipeline.pkl') # use joblib to load the pipeline\n",
    "\n",
    "# Now we do not have to preprocess the missing values in the new data, the pipeline will do it for us\n",
    "new_data = pd.DataFrame({\n",
    "    'age': [37, np.nan, 40], # one missing value numeric data\n",
    "    'income': [46000, 90000, np.nan], # one missing value numeric data\n",
    "    'gender': ['Female', 'Female', 'Male'], # categorical data\n",
    "    'education': ['PhD', 'Master', 'PhD'] # categorical data\n",
    "}) # Generate new synthetic data for demonstration\n",
    "\n",
    "\n",
    "new_predictions = loaded_pipeline.predict(new_data) # Make predictions using the loaded pipeline\n",
    "print(\"New Data Predictions:\") # Print the predictions\n",
    "print(new_predictions) # Print the predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
