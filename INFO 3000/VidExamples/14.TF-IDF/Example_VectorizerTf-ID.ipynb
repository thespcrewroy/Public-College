{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6060618-441b-46d6-a494-cacced685cfd",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer and CountWord Vectorizer, what they do and how to use them ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421f3382-9535-449c-ab05-861d4b048157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # import the TfidfVectorizer and CountVectorizer\n",
    "import pandas as pd # import the pandas library\n",
    "import numpy as np # import the numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee7c2a3-65c2-475d-afcd-01321c03aae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.','This document is the second document.','And this is the third one.','Is this the first document?']\n",
    "# The above is a corpus of text data\n",
    "# Each string can be considered a seperate document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf85dd7-703c-45ad-b0b0-a2ea919f4a6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example 1 - tfidf Vectorizer ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09dcbb50-8bae-4347-aeaf-af18e29a72ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparseform\n",
      "  (0, 1)\t0.46979138557992045\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 8)\t0.38408524091481483\n",
      "  (1, 5)\t0.5386476208856763\n",
      "  (1, 1)\t0.6876235979836938\n",
      "  (1, 6)\t0.281088674033753\n",
      "  (1, 3)\t0.281088674033753\n",
      "  (1, 8)\t0.281088674033753\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (3, 1)\t0.46979138557992045\n",
      "  (3, 2)\t0.5802858236844359\n",
      "  (3, 6)\t0.38408524091481483\n",
      "  (3, 3)\t0.38408524091481483\n",
      "  (3, 8)\t0.38408524091481483\n",
      "\n",
      "Features\n",
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "\n",
      "Shape: (4, 9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer() # Instantiate the object from the class\n",
    "X = vectorizer.fit_transform(corpus) # fit it to the data\n",
    "print(f\"Sparseform\\n{X}\\n\\nFeatures\\n{vectorizer.get_feature_names_out()}\\n\\nShape: {X.shape}\\n\") # print the sparse matrix, features, and shape\n",
    "# Because items in the matrix are 0's, it generates a simple vector.\n",
    "# The matrix is a sparse matrix, meaning most of the values are 0, and only a few are meaningful.\n",
    "# This sparse matrix saves memory.\n",
    "# The shape of the matrix is 4x9, because there are 4 documents and 9 unique words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a372dca-c7bc-4cd4-b52e-1e1fbd2d97a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary generated by tfidvectorizer\n",
    "# This it does automatically and acn be accessed through the method of the Class.\n",
    "vectorizer.vocabulary_ # creates a dictionary of the words and their index in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c7b5ef-f2c6-4851-bd07-fa12a16040e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Matrix:\n",
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n",
      "\n",
      " of shape: (4, 9)\n"
     ]
    }
   ],
   "source": [
    "# You can convert the tf-idf vector into a matrix of rows and columns\n",
    "# This the Term Document Matrix (TDM) that we discussed in the slides\n",
    "\n",
    "X_dense = X.toarray() # You can also do X.todense() to get a numpy array \n",
    "print(f\"Dense Matrix:\\n{X_dense}\\n\\n of shape: {X_dense.shape}\") # print the dense matrix and its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ec4412-666f-43f9-b754-c29365901260",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and  document     first        is       one    second       the  \\\n",
      "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
      "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
      "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "\n",
      "      third      this  \n",
      "0  0.000000  0.384085  \n",
      "1  0.000000  0.281089  \n",
      "2  0.511849  0.267104  \n",
      "3  0.000000  0.384085  \n"
     ]
    }
   ],
   "source": [
    "# Dataframe creation\n",
    "\n",
    "doc_matrix = pd.DataFrame(X_dense,columns=vectorizer.get_feature_names_out()) # Convert it into a dataframe to visualize\n",
    "print(doc_matrix) # print the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bcfdf6-3f5e-4cfd-b00a-bfbee956fcb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example 2 - including stopward removal ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d415a7e-6d0f-41d1-9f55-bac23bb16fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vect_stop = TfidfVectorizer(stop_words='english') # Using the stopwords parameter while vectorizing (before creating a matrix).\n",
    "# Check the docuementation for parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6cc7d00-50fd-4612-9bdd-7afe1ef0405a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t0.6166684570284895\n",
      "  (1, 0)\t0.78722297610404\n",
      "  (3, 0)\t1.0 \n",
      " ['document' 'second'] \n",
      " (4, 2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now tf-idf will be generated after removing stopwords\n",
    "\n",
    "X1 = vect_stop.fit_transform(corpus) # fit the vectorizer to the data\n",
    "print(X1,'\\n',vect_stop.get_feature_names_out(),'\\n',X1.shape,'\\n') # print the sparse matrix, features, and shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d3e76-be94-4aed-b850-c264c3ea23c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example 3 - CountWord Vectorizer ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b0ed10-edb5-492f-bbb3-459456e40beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparseform\n",
      "  (0, 8)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 1)\t1\n",
      "\n",
      "Features\n",
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "\n",
      "Shape: (4, 9)\n",
      "\n",
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "cvectorizer = CountVectorizer() # Instantiate the object from the class\n",
    "X2 = cvectorizer.fit_transform(corpus) # fit it to the data\n",
    "print(f\"Sparseform\\n{X2}\\n\\nFeatures\\n{cvectorizer.get_feature_names_out()}\\n\\nShape: {X2.shape}\\n\") # generates a sparse matrix\n",
    "print(cvectorizer.vocabulary_) # creates a dictionary of the words and their index in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72d6b9c-bbb8-4bc7-aeb3-dbcbf4019769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  document  first  is  one  second  the  third  this\n",
      "0    0         1      1   1    0       0    1      0     1\n",
      "1    0         2      0   1    0       1    1      0     1\n",
      "2    1         0      0   1    1       0    1      1     1\n",
      "3    0         1      1   1    0       0    1      0     1\n"
     ]
    }
   ],
   "source": [
    "# Dataframe creation \n",
    "\n",
    "doc_matrix1 = pd.DataFrame(X2.toarray(),columns=cvectorizer.get_feature_names_out()) # Convert it into a array to visualize\n",
    "print(doc_matrix1) # print the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716e22a-af29-4343-ac76-bdcf81880953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example 4 - How to use the vectorizers when building classifiers - shown with tfidf, but applies to CountVectorizer too ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7baa6cf7-3fdd-42e0-9463-00b8ca4a3be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data which could have labels attached to them as spam or not spam\n",
    "\n",
    "train = ('The sky is blue.','The sun is bright.') # The data which could have labels attached to them as spam or not spam\n",
    "test = ('The sun in the sky is bright', 'We can see the shining sun, the bright sun.') # The data which could have labels attached to them as spam or not spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f28c7d-72ed-4fe1-9def-63fecc21ef0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer object\n",
    "# use analyzer is word and stop_words is english which are responsible for remove stop words and create word vocabulary\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word' , stop_words='english') # Instantiate the object from the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd017283-fc2d-4222-9dbc-421a8a4d0ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sky': 2, 'blue': 0, 'sun': 3, 'bright': 1}\n"
     ]
    }
   ],
   "source": [
    "# Fit to training data and use the fitted vectorizer to transform training and test data\n",
    "# Note that we have to use the same, fitted, vectorizer object for all the text data\n",
    "\n",
    "tfidfvectorizer.fit(train) # fit the vectorizer to the training data\n",
    "tfidf_train = tfidfvectorizer.transform(train) # transform the training data\n",
    "tfidf_test  = tfidfvectorizer.transform(test) # transform the test data\n",
    "print(tfidfvectorizer.vocabulary_) # creates a dictionary of the words and their index in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3cda480-5f16-4f04-9cf2-ca17f5024fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix form train and test data : \n",
      "\n",
      "The training data matrix:\n",
      "[[0.70710678 0.         0.70710678 0.        ]\n",
      " [0.         0.70710678 0.         0.70710678]]\n",
      "\n",
      "The test data matrix:\n",
      "[[0.         0.57735027 0.57735027 0.57735027]\n",
      " [0.         0.4472136  0.         0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparse Matrix form train and test data : \\n\") # print the sparse matrix\n",
    "print(f\"The training data matrix:\\n{tfidf_train.toarray()}\\n\\nThe test data matrix:\\n{tfidf_test.toarray()}\") # print the training and test data matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd6301b-83d5-4629-8ddb-f79656ceca68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([1,0]).reshape(-1,1) # let us add some fake labels to the training data\n",
    "print(y_train) # print the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db51f5e-c983-4dd4-8ce0-2e7982feaf1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swapnilroy/miniconda3/envs/info2000/lib/python3.10/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So no we can do the usualmodel building process\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # import the logistic regression model\n",
    "lreg = LogisticRegression() # instantiate the object from the class\n",
    "lreg.fit(tfidf_train.toarray(),y_train) # fit the model to the training data\n",
    "lreg.predict(tfidf_test.toarray()) # predict the test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
