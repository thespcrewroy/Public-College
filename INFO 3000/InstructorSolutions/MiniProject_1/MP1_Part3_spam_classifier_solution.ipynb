{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "263cbbba-ca31-4244-81a1-9484cc219928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Instantiate lemmetizer and stopwords\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26a5a2b0-be56-4ec7-a4a2-beaf1fbf0308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                            message  class\n",
      "0      ham  Subject: enron methanol ; meter # : 988291\\r\\n...      0\n",
      "1      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...      0\n",
      "2      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...      0\n",
      "3     spam  Subject: photoshop , windows , office . cheap ...      1\n",
      "4      ham  Subject: re : indian springs\\r\\nthis deal is t...      0\n",
      "...    ...                                                ...    ...\n",
      "5166   ham  Subject: put the 10 on the ft\\r\\nthe transport...      0\n",
      "5167   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...      0\n",
      "5168   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...      0\n",
      "5169   ham  Subject: industrial worksheets for august 2000...      0\n",
      "5170  spam  Subject: important online banking alert\\r\\ndea...      1\n",
      "\n",
      "[5171 rows x 3 columns]\n",
      "Data types:\n",
      "message    object\n",
      "class       int64\n",
      "dtype: object\n",
      "\n",
      "Class counts:\n",
      "class\n",
      "0    3672\n",
      "1    1499\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data:\n",
      "                                             message  class\n",
      "0  Subject: enron methanol ; meter # : 988291\\r\\n...      0\n",
      "1  Subject: hpl nom for january 9 , 2001\\r\\n( see...      0\n",
      "2  Subject: neon retreat\\r\\nho ho ho , we ' re ar...      0\n",
      "3  Subject: photoshop , windows , office . cheap ...      1\n",
      "4  Subject: re : indian springs\\r\\nthis deal is t...      0\n",
      "\n",
      "Check for missing value:\n",
      "message    0\n",
      "class      0\n",
      "dtype: int64\n",
      "\n",
      "Shape of data(5171, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "\n",
    "data = pd.read_csv('spam_ham_dataset.csv')\n",
    "data = data.dropna()          # Drop any rows with missing data\n",
    "\n",
    "# Keep labels represented as numbers\n",
    "data = data.drop('label',axis=1)\n",
    "# data['class'] = data['label'].astype(int) # Convert the label column to integers (may not be required)\n",
    "print(f\"Data types:\\n{data.dtypes}\\n\\nClass counts:\\n{data['class'].value_counts()}\\n\\nData:\\n{data.head()}\")\n",
    "\n",
    "print(f\"\\nCheck for missing value:\\n{data.isna().sum()}\\n\\nShape of data{data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eee9a0ad-aef3-42cf-8e10-b03933682cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "\n",
    "def text_process(df):\n",
    "    df['message'] = df.message.str.lower()   # Convert to lowercase\n",
    "    df['message'] = df.message.apply(lambda x: ' '.join([word.replace(',','').replace(\"'\",'') for word in x.split()])) # Remove specific Punctuations\n",
    "    df['message'] = df.message.apply(lambda x: ' '.join([lem.lemmatize(word) for word in x.split()])) #Lemmatize\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a91a41ad-71d7-4b53-b88a-4ee53a31e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data:\n",
      "                                             message  class\n",
      "0  subject: enron methanol ; meter # : 988291 thi...      0\n",
      "1  subject: hpl nom for january 9 2001 ( see atta...      0\n",
      "2  subject: neon retreat ho ho ho we re around to...      0\n",
      "3  subject: photoshop window office . cheap . mai...      1\n",
      "4  subject: re : indian spring this deal is to bo...      0\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text\n",
    "\n",
    "data = text_process(data)\n",
    "\n",
    "print(f\"Preprocessed data:\\n{data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33d0ad69-f80e-4a4f-a251-f836e4716255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn modules\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12a3b176-1a2c-4216-90ba-23e31f8552e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    subject: enron methanol ; meter # : 988291 thi...\n",
       "1    subject: hpl nom for january 9 2001 ( see atta...\n",
       "2    subject: neon retreat ho ho ho we re around to...\n",
       "3    subject: photoshop window office . cheap . mai...\n",
       "4    subject: re : indian spring this deal is to bo...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate to X and y\n",
    "\n",
    "X = data.message\n",
    "y = data['class']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3243aec-f8ce-43d4-87cb-1e0bf588ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points for training: (3878,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)\n",
    "\n",
    "# Instantiate TF-IDF vectorizer with stop_words and fit on train data\n",
    "vectorize = TfidfVectorizer(stop_words='english',max_df=0.5)\n",
    "vectorize.fit(X_train)\n",
    "\n",
    "print(f\"Number of data points for training: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f46168b-08a5-4bf9-90b6-348b786418ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape(3878, 40693)\n",
      "\n",
      "Number of words in vocabilary: 40693\n"
     ]
    }
   ],
   "source": [
    "# Transform train and test data to tfidf matrices\n",
    "\n",
    "X_train = vectorize.transform(X_train)\n",
    "X_test = vectorize.transform(X_test)\n",
    "\n",
    "print(f\"Shape{X_train.todense().shape}\\n\\nNumber of words in vocabilary: {len(vectorize.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f3a80e5-858d-4f81-a90d-ec22501f327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy    8972\n",
      "cialis    10331\n",
      "phentermine    28899\n",
      "viagra    38389\n",
      "levitra    23604\n",
      "valium    38112\n",
      "xanax    39837\n",
      "prescription    29822\n",
      "doctor    14081\n",
      "pharmacy    28876\n",
      "overnight    28019\n"
     ]
    }
   ],
   "source": [
    "# Print sample of vocabulary\n",
    "count = 0\n",
    "for key in vectorize.vocabulary_:\n",
    "    if count < 11:\n",
    "        print(key,\"  \",vectorize.vocabulary_[key])\n",
    "        count = count + 1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cce83038-d719-4ec0-996c-70622b157f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glimpse of array:\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.19046898 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.19470216 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.37625006 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert to array matrices\n",
    "\n",
    "X_train = X_train.toarray()\n",
    "X_test =  X_test.toarray()\n",
    "\n",
    "print(f\"Glimpse of array:\\n{X_train[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81329716-32bb-4279-8db5-84e4ca48f3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.9296210363495746\n",
      "\n",
      "Confusion Matrix:\n",
      "[[929  90]\n",
      " [  1 273]]\n"
     ]
    }
   ],
   "source": [
    "# Model with Multinomomial Naive Bayes and metrics\n",
    "\n",
    "mnb = MultinomialNB() \n",
    "mnb.fit(X_train,y_train)\n",
    "mnb_pred = mnb.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy of model: {accuracy_score(mnb_pred,y_test)}\\n\\nConfusion Matrix:\\n{confusion_matrix(mnb_pred,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9b6fb0d-f887-4bb9-9e86-8a502ebcf048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.9466357308584686\n",
      "\n",
      "Confusion Matrix:\n",
      "[[899  38]\n",
      " [ 31 325]]\n"
     ]
    }
   ],
   "source": [
    "# Model with Gaussian Naive Bayes and metrics\n",
    "\n",
    "gnb =  GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb_pred = gnb.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy of model: {accuracy_score(gnb_pred,y_test)}\\n\\nConfusion Matrix:\\n{confusion_matrix(gnb_pred,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7366bdf4-9ac5-464c-877a-b751582e9c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.9791183294663574\n",
      "\n",
      "Confusion Matrix:\n",
      "[[909   6]\n",
      " [ 21 357]]\n"
     ]
    }
   ],
   "source": [
    "# Model with RFC and metrics\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy of model: {accuracy_score(rfc_pred,y_test)}\\n\\nConfusion Matrix:\\n{confusion_matrix(rfc_pred,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51945444-22eb-4b79-bbba-4d371616b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data to predict on\n",
    "\n",
    "email = [\"Hello George, how about a game of tennis tomorrow?\",\n",
    "         \"Hello, click here if you want drugs tonight\",\n",
    "         \"We offer free viagra!!! Click here now!!!\",\n",
    "         \"Dear Sara, I prepared the annual report.\",\n",
    "         \"Hi David, will we go for cinema tonight?\",\n",
    "         \"Best holidays offers only here!!!\",'Sir, Waiting for your mail.',\n",
    "         '#@Photoshop a fake image!',\n",
    "         'No problem. How are you doing?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0097766-bd9e-48cb-a393-a274f9195b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message\n",
      "0  hello george how about a game of tennis tomorrow?\n",
      "1          hello click here if you want drug tonight\n",
      "2          we offer free viagra!!! click here now!!!\n",
      "3            dear sara i prepared the annual report.\n",
      "4            hi david will we go for cinema tonight?\n",
      "5                    best holiday offer only here!!!\n",
      "6                         sir waiting for your mail.\n",
      "7                          #@photoshop a fake image!\n",
      "8                     no problem. how are you doing?\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe for new data\n",
    "emails = pd.DataFrame(email,columns=['message'])\n",
    "\n",
    "# Preprocess the same way as the original\n",
    "emails = text_process(emails)\n",
    "\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4baa9f86-8edb-4bbb-8915-bf400016d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello george how about a game of tennis tomorrow?     ham\n",
      "hello click here if you want drug tonight     spam\n",
      "we offer free viagra!!! click here now!!!     spam\n",
      "dear sara i prepared the annual report.     ham\n",
      "hi david will we go for cinema tonight?     ham\n",
      "best holiday offer only here!!!     spam\n",
      "sir waiting for your mail.     ham\n",
      "#@photoshop a fake image!     spam\n",
      "no problem. how are you doing?     ham\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF with the same vectorizer (always use the vectorizer that was used to fit the training data)\n",
    "# For me the best model was the Multinomial Naive Bayes with RandomForest being a very close 2nd.\n",
    "\n",
    "mapping = {1:\"spam\",0:\"ham\"}\n",
    "\n",
    "examples = vectorize.transform(emails['message'])\n",
    "predictions = mnb.predict(examples)\n",
    "\n",
    "# Print predictions\n",
    "\n",
    "for i,j in enumerate(predictions):\n",
    "    print(emails['message'].loc[i] + 5*\" \" + mapping[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad048880-ba47-436a-9b58-bcf1a4259ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
