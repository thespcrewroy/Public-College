{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b4eb2e-cdb7-4225-b712-982ade2a4a52",
   "metadata": {},
   "source": [
    "### Exercise 6a Solution  - RNN implementation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f2a757-20f8-4b3b-a2cf-7073e599e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad22886-cf22-4ed6-917a-e5b6b7f92233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialising the Variables\n",
    "\n",
    "n_features = 10 # Input which has 10 features (like the numeric representation of a word - word embedding)\n",
    "n_hidden_units = 4 # 4 neurons\n",
    "\n",
    "# Number of predicted outputs (y_t)\n",
    "n_output_units = 5  # for example, 5 classes in a classification problem\n",
    "\n",
    "# Random initialization for the sake of example\n",
    "np.random.seed(42)\n",
    "\n",
    "# Input, Weights, Bias\n",
    "x_t = np.random.randn(n_features)\n",
    "h_prev = np.random.randn(n_hidden_units)\n",
    "Wx = np.random.randn(n_hidden_units, n_features)\n",
    "Wh = np.random.randn(n_hidden_units, n_hidden_units)\n",
    "Wy = np.random.randn(n_output_units, n_hidden_units)\n",
    "b = np.random.randn(n_hidden_units)\n",
    "by = np.random.randn(n_output_units)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae0169b-95f2-4906-9c45-24e396e3a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function to be used in developing the predicted output for the cell\n",
    "\n",
    "def softmax(z):\n",
    "    t = np.exp(z)\n",
    "    a = np.exp(z) / np.sum(t, axis=1).reshape(-1,1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9b105b-0417-40f4-bb9f-8a91451ff20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to take the inputs as previous state,x and bias values to return the value of the next state using the RNN equation\n",
    "# Always check the dimensions of your results\n",
    "\n",
    "# RNN Basic function\n",
    "\n",
    "def rnn_step(x_t, h_prev, Wx, Wh, b):\n",
    "    \"\"\"\n",
    "    Perform a single RNN step.\n",
    "\n",
    "    Arguments:\n",
    "    x_t -- Current input data for timestep t, numpy array of shape (n_features,)\n",
    "    h_prev -- Previous hidden state, numpy array of shape (n_hidden_units,)\n",
    "    Wx -- Weight matrix multiplying the input, numpy array of shape (n_hidden_units, n_features)\n",
    "    Wh -- Weight matrix multiplying the hidden state, numpy array of shape (n_hidden_units, n_hidden_units)\n",
    "    b -- Bias vector, numpy array of shape (n_hidden_units,)\n",
    "\n",
    "    Returns:\n",
    "    h_next -- Next hidden state, numpy array of shape (n_hidden_units,)\n",
    "    \"\"\"\n",
    "    # Compute the next hidden state\n",
    "    h_next = np.tanh(np.dot(Wx, x_t) + np.dot(Wh, h_prev) + b)\n",
    "\n",
    "    return h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f5262c-c3f8-49c0-9153-c6d482cb7b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next hidden state: [ 0.46019631  0.2484162  -0.99331655  0.98477645]\n",
      "Shape of next hidden state: (4,)\n"
     ]
    }
   ],
   "source": [
    "# Compute next state using the RNN equation developed in the function\n",
    "# print the values and the shape\n",
    "# make sure the shape (dimension of output is what it should be. In this case (4,1)\n",
    "\n",
    "h_next = rnn_step(x_t, h_prev, Wx, Wh, b)\n",
    "\n",
    "print(f\"Next hidden state: {h_next}\\nShape of next hidden state: {h_next.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff40fc3-c41f-4253-9b58-ea1796533018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted output y:\n",
      "[ 1.73268879 -2.84585877  0.41448371  1.1214015   1.53971849]\n",
      "Predicted prbabilites of classes for this RNN Cell:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Shape: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "# Compute the prediction for the particular cell, which is y(t)\n",
    "# Use the provided softmax function\n",
    "# Feed the softmax the value of y_t but make sure it has a shape (5,1) and not just (5,)\n",
    "# Print the output as the probabilites of number of classification classes\n",
    "# Since the classes are 5 the output dimension should be the same.\n",
    "\n",
    "y_t = np.dot(Wy, h_next) + by\n",
    "\n",
    "y_probailities_of_classes = softmax(y_t.reshape(-1,1)) # Reshaping is done to make sure the array being fed is (n,1)\n",
    "\n",
    "print(f\"The predicted output y:\\n{y_t}\")\n",
    "print(f\"Predicted prbabilites of classes for this RNN Cell:\\n{y_probailities_of_classes}\\nShape: {y_probailities_of_classes.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
