{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3dadd4c-2d18-48c1-b25a-15226cb4e18c",
   "metadata": {},
   "source": [
    "### Exercise 6b Solution - Developing a function for the single LSTM cell using NumPy ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ccf89a-0f1b-40b0-84ea-52304607f006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2626bef-b42c-4acc-93c9-02cccfefd566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions for sigmoid and tanh computations.\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadc5ff3-8ab8-4402-a523-84d4dbb22dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Developing the LSTM eqautions ans returning the outputs of a LSTM Cell\n",
    "\n",
    "def lstm_step(x_t, h_prev, c_prev, Wf, Wi, Wo, Wc, bf, bi, bo, bc):\n",
    "    \"\"\"\n",
    "    Perform a single LSTM step.\n",
    "    \n",
    "    Arguments:\n",
    "    x_t -- Current input data for timestep t, numpy array of shape (n_features,)\n",
    "    h_prev -- Previous hidden state, numpy array of shape (n_hidden_units,)\n",
    "    c_prev -- Previous cell state, numpy array of shape (n_hidden_units,)\n",
    "    Wf, Wi, Wo, Wc -- Weight matrices for the forget, input, output gate, and cell state candidate\n",
    "    bf, bi, bo, bc -- Bias vectors for the forget, input, output gate, and cell state candidate\n",
    "    \n",
    "    Returns:\n",
    "    h_next -- Next hidden state, numpy array of shape (n_hidden_units,)\n",
    "    c_next -- Next cell state, numpy array of shape (n_hidden_units,)\n",
    "    \"\"\"\n",
    "    # Concatenate h_prev and x_t\n",
    "    #combined = np.hstack((h_prev, x_t))\n",
    "    combined = np.concatenate((h_prev, x_t),axis=0)\n",
    "    print(f\"After and before Concatenation shapes:\\n\\nConcatenated{combined.shape}\\nprev_state:{h_prev.shape}\\nInput x:{x_t.shape}\\n\\n\")\n",
    "\n",
    "    # Forget gate\n",
    "    f_t = sigmoid(np.dot(Wf, combined) + bf)\n",
    "\n",
    "    # Input gate\n",
    "    i_t = sigmoid(np.dot(Wi, combined) + bi)\n",
    "\n",
    "    # Cell state candidate\n",
    "    c_tilde_t = tanh(np.dot(Wc, combined) + bc)\n",
    "\n",
    "    # Output gate\n",
    "    o_t = sigmoid(np.dot(Wo, combined) + bo)\n",
    "\n",
    "    # Update cell state\n",
    "    c_next = f_t * c_prev + i_t * c_tilde_t\n",
    "\n",
    "    # Update hidden state\n",
    "    h_next = o_t * tanh(c_next)\n",
    "\n",
    "    return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3466b7e-bd7e-4201-a0f9-22d20c4b5b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialization of variables\n",
    "\n",
    "n_features = 10\n",
    "n_hidden_units = 4\n",
    "\n",
    "# Random initialization of the variables\n",
    "np.random.seed(42)\n",
    "\n",
    "# Input as an array with 10 features\n",
    "x_t = np.random.randn(n_features)\n",
    "\n",
    "# Previous state,cell values have to be the same as the number of neurons\n",
    "h_prev = np.random.randn(n_hidden_units)\n",
    "c_prev = np.random.randn(n_hidden_units)\n",
    "\n",
    "# Weights and Bias value initialization\n",
    "Wf = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "Wi = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "Wo = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "Wc = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "bf = np.random.randn(n_hidden_units)\n",
    "bi = np.random.randn(n_hidden_units)\n",
    "bo = np.random.randn(n_hidden_units)\n",
    "bc = np.random.randn(n_hidden_units)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6984738-0935-426e-866d-d605d6bfcf89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After and before Concatenation shapes:\n",
      "\n",
      "Concatenated(14,)\n",
      "prev_state:(4,)\n",
      "Input x:(10,)\n",
      "\n",
      "\n",
      "Next hidden state:\n",
      "[-0.24236866 -0.47552629 -0.61342184  0.2937933 ]\n",
      "\n",
      "Next cell state:\n",
      "[-2.00175213 -0.54923161 -1.26657864  0.33225723]\n"
     ]
    }
   ],
   "source": [
    "# Compute the outputs of the LSTM cell based on the function developed\n",
    "h_next, c_next = lstm_step(x_t, h_prev, c_prev, Wf, Wi, Wo, Wc, bf, bi, bo, bc)\n",
    "\n",
    "# Display the outputs\n",
    "# Since there are 4 neurons, we should have as output an simple one dimensional vector of 4 elements\n",
    "print(f\"Next hidden state:\\n{h_next}\")\n",
    "print(f\"\\nNext cell state:\\n{c_next}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597bd5d4-5227-45a8-b44c-57b08fad8446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
