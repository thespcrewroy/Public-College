{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM (Long Short-Term Memory) Networks:**\n",
    "---\n",
    "are a type of recurrent neural network (RNN) capable of learning long-term dependencies. An LSTM cell has three gates: the input gate, the forget gate, and the output gate. These gates determine what information should be stored, discarded, or passed to the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Guidelines**\n",
    "---\n",
    "* Implement a function in Python using NumPy that performs a single LSTM cell operation.\n",
    "* Inputs to the LSTM Function\n",
    "    * x_t: Input data for current timestep t. Shape: (n_features,)\n",
    "    * h_prev: Previous hidden state from the previous timestep. Shape: (n_hidden_units,)\n",
    "    * c_prev: Previous cell state from the previous timestep. Shape: (n_hidden_units,)\n",
    "    * Wf: Weight matrix for the forget gate (f_t). Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * Wi: Weight matrix for the input gate (i_t). Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * Wo: Weight matrix for the output gate (o_t). Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * Wc: Weight matrix for the cell state candidate. Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * bf: Bias vector for forget gate (f_t). Shape: (n_hidden_units,)\n",
    "    * bi: Bias vector for input gate (i_t). Shape: (n_hidden_units,)\n",
    "    * bo: Bias vector for output gate (o_t). Shape: (n_hidden_units,)\n",
    "    * bc: Bias vector for cell state candidate. Shape: (n_hidden_units,)\n",
    "* The function will produce the updated hidden state and cell state. \n",
    "* The hidden layer shall comprise of 4 neurons and there is a single layer.\n",
    "* Generate values for weights and bias with correct shapes, as NumPy arrays.\n",
    "* The equations to be implemented in the function: Input Gates Equation, Output Equations\n",
    "* Input Gates Equations:\n",
    "    * i_t = sigmoid(Wi[h_prev, x_t] + bi)\n",
    "    * f_t = sigmoid(Wf[h_prev, x_t] + bf)\n",
    "    * o_t = sigmoid(Wo[h_prev, x_t] + bo)\n",
    "* Output Equations:\n",
    "    * c_t_candidate = np.tanh(np.dot(Wc, unioned) + bc)\n",
    "    * c_t = f_t * c_prev + i_t * c_t_candidate\n",
    "    * h_t = o_t * np.tanh(c_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import Libraries'''\n",
    "import numpy as np # import numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Shape of Wf: (4, 14), \n",
      "Wi(4, 14), \n",
      "Wo: (4, 14), \n",
      "Wc: (4, 14), \n",
      "bf: (4,), \n",
      "bi: (4,), \n",
      "bo: (4,), \n",
      "bc: (4,)\n"
     ]
    }
   ],
   "source": [
    "# Initialization of variables\n",
    "\n",
    "n_features = 10\n",
    "n_hidden_units = 4\n",
    "\n",
    "# Random initialization of the variables\n",
    "np.random.seed(42)\n",
    "\n",
    "# Input as an array with 10 features\n",
    "x_t = np.random.randn(n_features)\n",
    "\n",
    "# Previous state,cell values have to be the same as the number of neurons\n",
    "h_prev = np.random.randn(n_hidden_units)\n",
    "c_prev = np.random.randn(n_hidden_units)\n",
    "\n",
    "# Weights and Bias value initialization\n",
    "Wf = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "Wi = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "Wo = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "Wc = np.random.randn(n_hidden_units, n_hidden_units + n_features)\n",
    "bf = np.random.randn(n_hidden_units)\n",
    "bi = np.random.randn(n_hidden_units)\n",
    "bo = np.random.randn(n_hidden_units)\n",
    "bc = np.random.randn(n_hidden_units)\n",
    "\n",
    "print(f\"\\n\\nShape of Wf: {Wf.shape}, \\nWi{Wi.shape}, \\nWo: {Wo.shape}, \\nWc: {Wc.shape}, \\nbf: {bf.shape}, \\nbi: {bi.shape}, \\nbo: {bo.shape}, \\nbc: {bc.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Implement a function in Python using NumPy that performs a single LSTM cell operation.'''\n",
    "def lstm_step(x_t, h_prev, c_prev, Wf, Wi, Wo, Wc, bf, bi, bo, bc):\n",
    "    \"\"\"\n",
    "    Perform a single LSTM step.\n",
    "\n",
    "    Arguments:\n",
    "    * x_t: Current input data for the timestep t. Shape: (n_features,)\n",
    "    * h_prev: Previous hidden state. Shape: (n_hidden_units,)\n",
    "    * c_prev: Previous cell state. Shape: (n_hidden_units,)\n",
    "    * Wf: Weight matrix for the forget gate (f_t). Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * Wi: Weight matrix for the input gate (i_t). Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * Wo: Weight matrix for the output gate (o_t). Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * Wc: Weight matrix for the cell state candidate. Shape: (n_hidden_units, n_hidden_units + n_features)\n",
    "    * bf: Bias vector for forget gate (f_t). Shape: (n_hidden_units,)\n",
    "    * bi: Bias vector for input gate (i_t). Shape: (n_hidden_units,)\n",
    "    * bo: Bias vector for output gate (o_t). Shape: (n_hidden_units,)\n",
    "    * bc: Bias vector for cell state candidate. Shape: (n_hidden_units,)\n",
    "\n",
    "    Returns:\n",
    "    * h_next -- Next hidden state, numpy array of shape (n_hidden_units,)\n",
    "    * c_next -- Next cell state, numpy array of shape (n_hidden_units,)\n",
    "    \"\"\"\n",
    "\n",
    "    '''Setup'''\n",
    "    unioned = np.concatenate((h_prev, x_t), axis=0) # Concatenate the input x_t and the previous hidden state h_prev\n",
    "    print(f\"After and before Concatenation shapes:\\n\\nConcatenated{unioned.shape}\\nprev_state:{h_prev.shape}\\nInput x:{x_t.shape}\\n\\n\")\n",
    "\n",
    "\n",
    "    '''Input Gates Equations'''\n",
    "    i_t = sigmoid(np.dot(Wi, unioned) + bi) # Input gate\n",
    "    f_t = sigmoid(np.dot(Wf, unioned) + bf) # Forget gate\n",
    "    o_t = sigmoid(np.dot(Wo, unioned) + bo) # Output gate\n",
    "\n",
    "    '''Outputs Equations'''\n",
    "    c_t_candidate = np.tanh(np.dot(Wc, unioned) + bc) # Cell state candidate\n",
    "    c_t = f_t * c_prev + i_t * c_t_candidate # Cell state\n",
    "    h_t = o_t * np.tanh(c_t) # Hidden state update\n",
    "\n",
    "    return h_t, c_t # Return the hidden state and the cell state\n",
    "\n",
    "\n",
    "def sigmoid(x): # represents the sigmoid activation function\n",
    "    return 1 / (1 + np.exp(-x)) # sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After and before Concatenation shapes:\n",
      "\n",
      "Concatenated(14,)\n",
      "prev_state:(4,)\n",
      "Input x:(10,)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Perform a single LSTM step'''\n",
    "h_next, c_next = lstm_step(x_t, h_prev, c_prev, Wf, Wi, Wo, Wc, bf, bi, bo, bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next hidden state (h_next): [-0.24236866 -0.47552629 -0.61342184  0.2937933 ]\n",
      "Next cell state (c_next): [-2.00175213 -0.54923161 -1.26657864  0.33225723]\n"
     ]
    }
   ],
   "source": [
    "'''Print the results'''\n",
    "print(\"Next hidden state (h_next):\", h_next)\n",
    "print(\"Next cell state (c_next):\", c_next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
