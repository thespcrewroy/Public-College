{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # Natural Language Toolkit\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize # Tokenizers\n",
    "from nltk.corpus import stopwords # Stopwords\n",
    "import pandas as pd # Import the Pandas library\n",
    "import numpy as np # Import the NumPy library\n",
    "from nltk.stem import PorterStemmer # Import the PorterStemmer function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # import the TfidfVectorizer and CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [ \"The cat sat on the mat!\", \"Dogs are sitting on the log. Dogs love logs.\", \"Cats are lying on the rug, but the cat prefers the mat.\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the cat sat on the mat!',\n",
       " 'dogs are sitting on the log. dogs love logs.',\n",
       " 'cats are lying on the rug, but the cat prefers the mat.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Convert text to lowercase'''\n",
    "preprocessed_text = [ document.lower() for document in text ] # Convert text to lowercase using list comprehension\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'cat', 'sat', 'on', 'the', 'mat', '!'],\n",
       " ['dogs',\n",
       "  'are',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'the',\n",
       "  'log',\n",
       "  '.',\n",
       "  'dogs',\n",
       "  'love',\n",
       "  'logs',\n",
       "  '.'],\n",
       " ['cats',\n",
       "  'are',\n",
       "  'lying',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rug',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'cat',\n",
       "  'prefers',\n",
       "  'the',\n",
       "  'mat',\n",
       "  '.']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Tokenize text into words'''\n",
    "preprocessed_text = [ word_tokenize(document) for document in preprocessed_text ] # Tokenize text into words\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'cat', 'sat', 'on', 'the', 'mat'],\n",
       " ['dogs', 'are', 'sitting', 'on', 'the', 'log', 'dogs', 'love', 'logs'],\n",
       " ['cats',\n",
       "  'are',\n",
       "  'lying',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rug',\n",
       "  'but',\n",
       "  'the',\n",
       "  'cat',\n",
       "  'prefers',\n",
       "  'the',\n",
       "  'mat']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Remove non-alphabetic tokens'''\n",
    "preprocessed_text = [ [ token for token in document if token.isalpha() ] for document in preprocessed_text ] # Add only alphabetic tokens to the filtered_text list for each document in the preprocessed_text list\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cat', 'sat', 'mat'],\n",
       " ['dogs', 'sitting', 'log', 'dogs', 'love', 'logs'],\n",
       " ['cats', 'lying', 'rug', 'cat', 'prefers', 'mat']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Remove stop words'''\n",
    "stop_words = set(stopwords.words(\"english\")) # Get the set of English stopwords\n",
    "preprocessed_text = [ [ token for token in document if token not in stop_words ] for document in preprocessed_text ] # Add only non-stopwords to the filtered_text list for each document in the preprocessed_text list\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a Function To Do the Preprocessing On Each Individual Document In Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the mat!</td>\n",
       "      <td>cat sat mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dogs are sitting on the log. Dogs love logs.</td>\n",
       "      <td>dog sit log dog love log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cats are lying on the rug, but the cat prefers...</td>\n",
       "      <td>cat lie rug cat prefer mat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                            The cat sat on the mat!   \n",
       "1       Dogs are sitting on the log. Dogs love logs.   \n",
       "2  Cats are lying on the rug, but the cat prefers...   \n",
       "\n",
       "                  cleaned_text  \n",
       "0                 cat sat mat   \n",
       "1    dog sit log dog love log   \n",
       "2  cat lie rug cat prefer mat   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the array to a DataFrame\n",
    "data = pd.DataFrame(text, columns=['text'])\n",
    "\n",
    "# Define the preprocessing function\n",
    "def clean_text(text):\n",
    "    cleaned_text = \"\"\n",
    "\n",
    "    # Create the stop words set\n",
    "    stem = PorterStemmer() # Instantiate the stemmer object\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    # Use a loop to filter out non-alphabetic characters and stopwords\n",
    "    for word in text: # Loop through each word in the text\n",
    "        if word.isalpha() and word not in stop_words: # Check if the word is alphabetic and not a stopword\n",
    "            cleaned_text = cleaned_text + stem.stem(word) + \" \" # Stem and append the word to the filtered_text string\n",
    "    \n",
    "    return cleaned_text # Return the filtered_text string\n",
    "\n",
    "# Apply the preprocessing function to the text column\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Print the preprocessed data\n",
    "print(\"Preprocessed Data:\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Array for CountVectorizer and TF-IDF Vectorizer matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVector Matrix:\n",
      "[[1 0 0 0 0 1 0 0 1 0]\n",
      " [0 2 0 2 1 0 0 0 0 1]\n",
      " [2 0 1 0 0 1 1 1 0 0]]\n",
      "\n",
      "Features\n",
      "['cat' 'dog' 'lie' 'log' 'love' 'mat' 'prefer' 'rug' 'sat' 'sit']\n",
      "\n",
      "Shape: (3, 10)\n",
      "\n",
      "{'cat': 0, 'sat': 8, 'mat': 5, 'dog': 1, 'sit': 9, 'log': 3, 'love': 4, 'lie': 2, 'rug': 7, 'prefer': 6}\n"
     ]
    }
   ],
   "source": [
    "cvectorizer = CountVectorizer() # Instantiate the object from the class\n",
    "X2 = cvectorizer.fit_transform(data['cleaned_text']) # fit it to the data\n",
    "X_dense = X2.todense() # convert the sparse matrix to a dense matrix\n",
    "print(f\"CountVector Matrix:\\n{X_dense}\\n\\nFeatures\\n{cvectorizer.get_feature_names_out()}\\n\\nShape: {X2.shape}\\n\") # generates a dense matrix\n",
    "print(cvectorizer.vocabulary_) # creates a dictionary of the words and their index in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>lie</th>\n",
       "      <th>log</th>\n",
       "      <th>love</th>\n",
       "      <th>mat</th>\n",
       "      <th>prefer</th>\n",
       "      <th>rug</th>\n",
       "      <th>sat</th>\n",
       "      <th>sit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat  dog  lie  log  love  mat  prefer  rug  sat  sit\n",
       "0    1    0    0    0     0    1       0    0    1    0\n",
       "1    0    2    0    2     1    0       0    0    0    1\n",
       "2    2    0    1    0     0    1       1    1    0    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_matrix1 = pd.DataFrame(X2.toarray(),columns=cvectorizer.get_feature_names_out()) # Convert it into a array to visualize\n",
    "doc_matrix1 # print the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-IDF Matrix:\n",
      "[[0.51785612 0.         0.         0.         0.         0.51785612\n",
      "  0.         0.         0.68091856 0.        ]\n",
      " [0.         0.63245553 0.         0.63245553 0.31622777 0.\n",
      "  0.         0.         0.         0.31622777]\n",
      " [0.62663214 0.         0.41197298 0.         0.         0.31331607\n",
      "  0.41197298 0.41197298 0.         0.        ]]\n",
      "\n",
      "Features\n",
      "['cat' 'dog' 'lie' 'log' 'love' 'mat' 'prefer' 'rug' 'sat' 'sit']\n",
      "\n",
      "Shape: (3, 10)\n",
      "\n",
      "{'cat': 0, 'sat': 8, 'mat': 5, 'dog': 1, 'sit': 9, 'log': 3, 'love': 4, 'lie': 2, 'rug': 7, 'prefer': 6}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer() # instantiate the object from the class\n",
    "X = vectorizer.fit_transform(data['cleaned_text']) # fit it to the data\n",
    "X_dense = X.toarray() # convert the sparse matrix to a dense matrix\n",
    "print(f\"Tf-IDF Matrix:\\n{X_dense}\\n\\nFeatures\\n{vectorizer.get_feature_names_out()}\\n\\nShape: {X.shape}\\n\")\n",
    "print(vectorizer.vocabulary_) # creates a dictionary of the words and their index in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>lie</th>\n",
       "      <th>log</th>\n",
       "      <th>love</th>\n",
       "      <th>mat</th>\n",
       "      <th>prefer</th>\n",
       "      <th>rug</th>\n",
       "      <th>sat</th>\n",
       "      <th>sit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313316</td>\n",
       "      <td>0.411973</td>\n",
       "      <td>0.411973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat       dog       lie       log      love       mat    prefer  \\\n",
       "0  0.517856  0.000000  0.000000  0.000000  0.000000  0.517856  0.000000   \n",
       "1  0.000000  0.632456  0.000000  0.632456  0.316228  0.000000  0.000000   \n",
       "2  0.626632  0.000000  0.411973  0.000000  0.000000  0.313316  0.411973   \n",
       "\n",
       "        rug       sat       sit  \n",
       "0  0.000000  0.680919  0.000000  \n",
       "1  0.000000  0.000000  0.316228  \n",
       "2  0.411973  0.000000  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Convert the array to a DataFrame'''\n",
    "doc_matrix = pd.DataFrame(X_dense,columns=vectorizer.get_feature_names_out()) # Convert it into a dataframe to visualize it\n",
    "doc_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
