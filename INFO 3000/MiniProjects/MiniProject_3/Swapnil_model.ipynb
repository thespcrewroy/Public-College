{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines\n",
    "* (✔) You are given a dataset with 2 features and a label\n",
    "* (✔) Preprocess in Jupyter Notebook\n",
    "    * (✔) Deal with missing values\n",
    "    * (✔) Deal with categorical features\n",
    "    * (✔) Build the preprocessing with the pipeline class\n",
    "* (✔) Build the model with Jupyter Notebook\n",
    "    * (✔) Classification Algorithm\n",
    "    * (✔) Hyperparameter tuning if necessary\n",
    "    * (✔) Accuracy of >= 70%\n",
    "* (✔) Save the model and preprocessing as 'model.pkl' using the joblib module\n",
    "* You have to build a flask-based web app\n",
    "    * (✔) 2 routes\n",
    "    * (✔) Gathering valid inputs from the client\n",
    "    * (✔) Predicting based on the inputs and serving the prediction back\n",
    "        * (✔) Load the saved model for predictions\n",
    "    * (✔) Interface for the client to feed inputs and see prediction\n",
    "        * (✔) Developed with a single HTML page\n",
    "        * (✔) Prediction returned once the client presses \"Submit\"\n",
    "        * (✔) Warning and wait for correct inputs if the client does not enter an input or gives the wrong inputs\n",
    "    * (✔) Optional: CSS Styling\n",
    "* (✔) Deploy the predictive model\n",
    "    * (✔) Serve the saved model for any client to use\n",
    "    * (✔) User should be able to enter in data and get a prediction\n",
    "* (✔) Answer the Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading\n",
    "* WebApp runs flawlessly, as per above specification and gives predictions - 60%\n",
    "* Model was built correctly, including all preprocessing using the \"Pipeline\" class - 15%\n",
    "* Model was developed with an accuracy of 70% or above - 15%\n",
    "* Questions below are answered - 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import standard data sceince libraries'''\n",
    "from matplotlib import pyplot as plt # used for plotting graphs\n",
    "import pandas as pd # used for data manipulation and analysis\n",
    "import numpy as np # used for numerical computing\n",
    "import os # used for file handling\n",
    "import joblib # used to save the model\n",
    "\n",
    "'''Import sklearn libraries'''\n",
    "from sklearn.preprocessing import StandardScaler # used for scaling data\n",
    "from sklearn.preprocessing import OneHotEncoder # used for encoding data\n",
    "from sklearn.model_selection import train_test_split # used for splitting dataset\n",
    "from sklearn.metrics import accuracy_score # used for evaluating model\n",
    "from sklearn.compose import ColumnTransformer # used to apply different preprocessing to different columns\n",
    "from sklearn.pipeline import Pipeline # used to chain together different transformers\n",
    "from sklearn.impute import SimpleImputer # used to fill in missing values\n",
    "\n",
    "'''Different Classification Algorithms'''\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest classifier\n",
    "from sklearn.svm import SVC # support vector machine classifier\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression classifier\n",
    "from sklearn.model_selection import GridSearchCV # used for hyperparameter tuning\n",
    "from sklearn.tree import DecisionTreeClassifier # decision tree classifier\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes classifier\n",
    "\n",
    "\n",
    "'''Import warnings module to ignore warnings'''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "        Test Group  label\n",
      "0  0.496714     C      1\n",
      "1 -0.138264     C      1\n",
      "2       NaN     B      0\n",
      "3  1.523030     B      0\n",
      "4 -0.234153     A      0\n",
      "5 -0.234137     A      0\n",
      "6  1.579213     B      1\n",
      "7  0.767435     C      1\n",
      "8 -0.469474     B      1\n",
      "9       NaN     C      1\n"
     ]
    }
   ],
   "source": [
    "'''Read the data'''\n",
    "data = pd.read_csv('MP3_Dataset.csv') # read the data\n",
    "print(f\"Data:\\n {data.head(10)}\") # print the first 10 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "        Test Group\n",
      "0  0.496714     C\n",
      "1 -0.138264     C\n",
      "2       NaN     B\n",
      "3  1.523030     B\n",
      "4 -0.234153     A\n",
      "5 -0.234137     A\n",
      "6  1.579213     B\n",
      "7  0.767435     C\n",
      "8 -0.469474     B\n",
      "9       NaN     C \n",
      "\n",
      "Labels:\n",
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''Seperate the data into features and labels'''\n",
    "X = data.drop('label', axis=1) # drop the label column from the data and assign the rest to X\n",
    "y = data['label'] # assign the label column to y\n",
    "print(f\"Features:\\n {X.head(10)} \\n\\nLabels:\\n{y.head(10)}\") # print the first 10 rows of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in different features:\n",
      "Test     10\n",
      "Group     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''Print the number of missing values in the data'''\n",
    "print(f\"Missing values in different features:\\n{X.isna().sum()}\") # print the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Seperate feature type to help define which colums to be processed by the transformer'''\n",
    "numerical_feature = ['Test'] # numerical feature\n",
    "categorical_feature = ['Group'] # categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split the data into training and testing set'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Build the preprocessing pipeline'''\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # fill in numeric missing values with the mean of the column\n",
    "    ('scaler', StandardScaler()) # scale the numerical data to have a mean of 0 and a standard deviation of 1\n",
    "]) # Build the numeric transformer\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # fill in categorical missing values with the mode of the column\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')) # encode the categorical data into a one-hot encoded format\n",
    "]) # Build the categorical transformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_feature), # use the numeric_transformer on the numerical_features\n",
    "        ('cat', categorical_transformer, categorical_feature) # use the categorical_transformer on the categorical_features\n",
    "    ]) # Combine the transformers into a single preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tuning 5 Classification Models to Various Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 324 candidates, totalling 4860 fits\n",
      "Best Parameters:  {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Best Score: 87.56%\n"
     ]
    }
   ],
   "source": [
    "'''Building a Random Forest Classifier'''\n",
    "rfc = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
    "}\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=15, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "rfc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', grid_search_rfc)])\n",
    "rfc_pipeline.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \", rfc_pipeline.named_steps['classifier'].best_params_)\n",
    "print(f\"Best Score: {rfc_pipeline.named_steps['classifier'].best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 480 candidates, totalling 7200 fits\n",
      "Best Parameters:  {'C': 1, 'coef0': 1.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Best Score: 79.56%\n"
     ]
    }
   ],
   "source": [
    "'''Building a Support Vector Machine Classifier'''\n",
    "svc = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], # Kernel type\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel (only for 'poly')\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0]  # Independent term in kernel function (only for 'poly' and 'sigmoid')\n",
    "}\n",
    "grid_search_svc = GridSearchCV(estimator=svc, param_grid=param_grid, cv=15, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "svc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', grid_search_svc)])\n",
    "svc_pipeline.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \", svc_pipeline.named_steps['classifier'].best_params_)\n",
    "print(f\"Best Score: {svc_pipeline.named_steps['classifier'].best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 80 candidates, totalling 1200 fits\n",
      "Best Parameters:  {'C': 1, 'max_iter': 20, 'penalty': 'l2'}\n",
      "Best Score: 76.00%\n"
     ]
    }
   ],
   "source": [
    "'''Building a Logistic Regression Classifier'''\n",
    "logreg = LogisticRegression()\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Regularization type\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'max_iter': [20, 50, 100, 200]  # Maximum number of iterations\n",
    "}\n",
    "grid_search_logreg = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=15, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "logreg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', grid_search_logreg)])\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \", logreg_pipeline.named_steps['classifier'].best_params_)\n",
    "print(f\"Best Score: {logreg_pipeline.named_steps['classifier'].best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1008 candidates, totalling 15120 fits\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 27, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'random'}\n",
      "Best Score: 87.78%\n"
     ]
    }
   ],
   "source": [
    "'''Decision Tree Classifier'''\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "    'splitter': ['best', 'random'],    # Strategy used to choose the split at each node\n",
    "    'max_depth': [None, 3, 6, 9, 18, 27, 36],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
    "}\n",
    "grid_search_dt = GridSearchCV(estimator=dt, param_grid=param_grid, cv=15, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "dt_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', grid_search_dt)])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \", dt_pipeline.named_steps['classifier'].best_params_)\n",
    "print(f\"Best Score: {dt_pipeline.named_steps['classifier'].best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 5 candidates, totalling 75 fits\n",
      "Best Parameters:  {'var_smoothing': 1e-09}\n",
      "Best Score: 74.89%\n"
     ]
    }
   ],
   "source": [
    "'''Naive Bayes Classifier'''\n",
    "gnb = GaussianNB()\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-09, 1e-08, 1e-07, 1e-06, 1e-05]  # Portion of the largest variance of all features\n",
    "}\n",
    "grid_search_gnb = GridSearchCV(estimator=gnb, param_grid=param_grid, cv=15, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "gnb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', grid_search_gnb)])\n",
    "gnb_pipeline.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \", gnb_pipeline.named_steps['classifier'].best_params_)\n",
    "print(f\"Best Score: {gnb_pipeline.named_steps['classifier'].best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the Classification Models on the training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Instantiate Models With Best Parameters'''\n",
    "rfc = RandomForestClassifier(max_depth=None, max_features='log2', min_samples_leaf=4, min_samples_split=5, n_estimators=50)\n",
    "svc = SVC(C=1, coef0=1.0, degree=2, gamma='auto', kernel='sigmoid')\n",
    "logreg = LogisticRegression(C=1, max_iter=20, penalty='l2')\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=9, max_features='log2', min_samples_leaf=2, min_samples_split=5, splitter='best')\n",
    "gnb = GaussianNB(var_smoothing=1e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Build the model pipelines'''\n",
    "# Random Forest Classifier\n",
    "rfc_test_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), # preprocess the data\n",
    "    ('classifier', rfc) # classify the data using a random forest classifier\n",
    "]) # Build the model\n",
    "\n",
    "# SVM Classifier\n",
    "svc_test_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), # preprocess the data\n",
    "    ('classifier', svc) # classify the data using a random forest classifier\n",
    "]) # Build the model\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "logreg_test_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), # preprocess the data\n",
    "    ('classifier', logreg) # classify the data using a random forest classifier\n",
    "]) # Build the model\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_test_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), # preprocess the data\n",
    "    ('classifier', dt) # classify the data using a random forest classifier\n",
    "]) # Build the model\n",
    "\n",
    "# Gaussian Naive Bays Classifier\n",
    "gnb_test_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), # preprocess the data\n",
    "    ('classifier', gnb) # classify the data using a random forest classifier\n",
    "]) # Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Train and Test the Models'''\n",
    "# Random Forest Classifier\n",
    "rfc_test_pipeline.fit(X_train, y_train) # fit the model on the training data\n",
    "y_pred_rfc = rfc_test_pipeline.predict(X_test) # predict the labels of the test data\n",
    "\n",
    "# SVM Classifier\n",
    "svc_test_pipeline.fit(X_train, y_train) # fit the model on the training data\n",
    "y_pred_svm = svc_test_pipeline.predict(X_test) # predict the labels of the test data\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "logreg_test_pipeline.fit(X_train, y_train) # fit the model on the training data\n",
    "y_pred_logreg = logreg_test_pipeline.predict(X_test) # predict the labels of the test data\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_test_pipeline.fit(X_train, y_train) # fit the model on the training data\n",
    "y_pred_dt = dt_test_pipeline.predict(X_test) # predict the labels of the test data\n",
    "\n",
    "# Gaussian Naive Bays Classifier\n",
    "gnb_test_pipeline.fit(X_train, y_train) # fit the model on the training data\n",
    "y_pred_gnb = gnb_test_pipeline.predict(X_test) # predict the labels of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7\n",
      "SVM Accuracy: 0.65\n",
      "Logistic Regression Accuracy: 0.7\n",
      "Decision Tree Accuracy: 0.65\n",
      "Gaussian Naive Bayes Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "'''Evaluate the models'''\n",
    "# Random Forest Classifier\n",
    "rfc_acc = accuracy_score(y_test, y_pred_rfc) # calculate the accuracy of the model\n",
    "print(f\"Random Forest Accuracy: {rfc_acc}\") # print the accuracy of the model\n",
    "\n",
    "# SVM Classifier\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm) # calculate the accuracy of the model\n",
    "print(f\"SVM Accuracy: {svm_acc}\") # print the accuracy of the model\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "lr_acc = accuracy_score(y_test, y_pred_logreg) # calculate the accuracy of the model\n",
    "print(f\"Logistic Regression Accuracy: {lr_acc}\") # print the accuracy of the model\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_acc = accuracy_score(y_test, y_pred_dt) # calculate the accuracy of the model\n",
    "print(f\"Decision Tree Accuracy: {dt_acc}\") # print the accuracy of the model\n",
    "\n",
    "# Gaussian Naive Bays Classifier\n",
    "gnb_acc = accuracy_score(y_test, y_pred_gnb) # calculate the accuracy of the model\n",
    "print(f\"Gaussian Naive Bayes Accuracy: {gnb_acc}\") # print the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Looks like Gaussian Naive Bayes performs the best out of the other models\n",
    "* #### It has a 0.75 test accuracy score, which is well above the 0.70 threshold\n",
    "* #### So let's build our model around it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Save the model with the best accuracy as model.pkl'''\n",
    "joblib.dump(gnb_test_pipeline, 'model.pkl') # save the model as model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. What did you specifically do to get an accuracy of 70% or above for the model?\n",
    "* Ans) I first listed all of the classification models we did during the year. I then picked the 5 that the instructor had done examples for (Random Forest, Logistic Regression, Decision Tree, Naive Bayes, and SVM). I looked at the documentation for the models in sklearn's docs to determine the most common hyperparameters for each of them. I then plugged a selection of the hyperparameters into GridSearchCV to find the best hyperparamters for each model and also to see their training accuracy. After I was done, I added them into the pipeline and evaluted them on the test data. From this, I found that Gaussian Naive Bayes performed the best with a test acuracy of 75%. Interstingly, this model had the lowest train accuracy, however, that was also still above 70%. This shows that there is an equal and oppsite force between the validation and train error, so it is necessary to balance these to avoid both overfitting and underfitting.\n",
    "\n",
    "2. What were the challenges you faced and how did you address them / solve them in building the flask-based app?\n",
    "* Ans) The main challenge I faced when building the flask app was issuing warnings to the user. For this, I threw ValueError exceptions if the user inputted the wrong information. Any other exceptions are printed as a stack trace to the user. This sort of correlates to another challenge in that I did not know if I needed to define ranges for user input of the \"Test Value\" since the model is only trained on a certain range. Thus, I eventually decided to round to the lowest and highest whole numbers of the model so that it can provide insights onto its scope.\n",
    "\n",
    "3. What were your key takeaways / learning from this course.\n",
    "* Ans) From this course, my biggest takeaway was learning preprocessing techniques. Models are easy as they are simply plug and chug with some parameter or hyperparameter tuning from looking at the documentation. However, understanding the preprocessing that goes behind making data ready is perhaps the most challenging part about this course and is something I learned the most. From TF-IDF vectorizers, to tensors, to pipelines, to lemmatization, to onehotencoding, and so much more, preprocessing is definetly the key valuable takeaway/learning from this course"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
